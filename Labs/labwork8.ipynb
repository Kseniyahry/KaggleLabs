{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aacd8b2d",
   "metadata": {
    "papermill": {
     "duration": 0.003143,
     "end_time": "2025-11-13T17:59:00.855315",
     "exception": false,
     "start_time": "2025-11-13T17:59:00.852172",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data and Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785628cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T17:59:00.861185Z",
     "iopub.status.busy": "2025-11-13T17:59:00.860956Z",
     "iopub.status.idle": "2025-11-13T18:05:28.569426Z",
     "shell.execute_reply": "2025-11-13T18:05:28.568778Z"
    },
    "papermill": {
     "duration": 387.712667,
     "end_time": "2025-11-13T18:05:28.570533",
     "exception": false,
     "start_time": "2025-11-13T17:59:00.857866",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13100/13100 [06:25<00:00, 33.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing done.\n"
     ]
    }
   ],
   "source": [
    "import librosa, soundfile as sf, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1\"\n",
    "WAV_DIR = os.path.join(DATA_DIR, \"wavs\")\n",
    "OUT_DIR = \"processed_keras\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 80\n",
    "\n",
    "metadata = pd.read_csv(os.path.join(DATA_DIR, \"metadata.csv\"), sep=\"|\", header=None)\n",
    "metadata.columns = [\"id\", \"raw\", \"text\"]\n",
    "\n",
    "def preprocess_audio(path):\n",
    "    wav, sr = sf.read(path)\n",
    "    if len(wav.shape) > 1:\n",
    "        wav = np.mean(wav, axis=1)\n",
    "    if sr != SAMPLE_RATE:\n",
    "        wav = librosa.resample(y=wav, orig_sr=sr, target_sr=SAMPLE_RATE)\n",
    "    wav = wav / np.max(np.abs(wav))\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=wav, sr=SAMPLE_RATE, n_mels=N_MELS, n_fft=400, hop_length=160\n",
    "    )\n",
    "    mel_db = np.log1p(mel)\n",
    "    return mel_db.T.astype(np.float32), len(wav) / SAMPLE_RATE\n",
    "\n",
    "rows = []\n",
    "spec_dir = os.path.join(OUT_DIR, \"specs\")\n",
    "os.makedirs(spec_dir, exist_ok=True)\n",
    "\n",
    "for i, row in tqdm(metadata.iterrows(), total=len(metadata)):\n",
    "    wav_path = os.path.join(WAV_DIR, row[\"id\"] + \".wav\")\n",
    "    mel, dur = preprocess_audio(wav_path)\n",
    "    np.save(f\"{spec_dir}/{i:06d}.npy\", mel)\n",
    "    rows.append(\n",
    "        {\"spec_path\": f\"{spec_dir}/{i:06d}.npy\", \"text\": row[\"text\"], \"duration\": dur}\n",
    "    )\n",
    "\n",
    "manifest = pd.DataFrame(rows)\n",
    "manifest.to_csv(os.path.join(OUT_DIR, \"manifest.csv\"), index=False)\n",
    "print(\"Preprocessing done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697ba6ba",
   "metadata": {
    "papermill": {
     "duration": 0.121494,
     "end_time": "2025-11-13T18:05:28.816782",
     "exception": false,
     "start_time": "2025-11-13T18:05:28.695288",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Generator with tf.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dfd9d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:05:29.057851Z",
     "iopub.status.busy": "2025-11-13T18:05:29.057534Z",
     "iopub.status.idle": "2025-11-13T18:05:55.487974Z",
     "shell.execute_reply": "2025-11-13T18:05:55.487335Z"
    },
    "papermill": {
     "duration": 26.553533,
     "end_time": "2025-11-13T18:05:55.489318",
     "exception": false,
     "start_time": "2025-11-13T18:05:28.935785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-13 18:05:32.389722: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1763057132.866480      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1763057132.980715      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1763057155.104627      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1763057155.105360      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import string\n",
    "import librosa, soundfile as sf, numpy as np, pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "DATA_DIR = \"/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1\"\n",
    "WAV_DIR = os.path.join(DATA_DIR, \"wavs\")\n",
    "OUT_DIR = \"processed_keras\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 80\n",
    "\n",
    "\n",
    "alphabet = list(string.ascii_lowercase) + [\" \", \"'\", \"<blank>\"]\n",
    "char2idx = {c: i for i, c in enumerate(alphabet)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "def prepare_inputs(mel, text):\n",
    "    input_len = [mel.shape[0] // 2]  # приблизно після Conv шарів\n",
    "    label_len = [len(text)]\n",
    "    return {\n",
    "        \"spectrogram\": mel,\n",
    "        \"labels\": text,\n",
    "        \"input_length\": np.array(input_len, dtype=np.int32),\n",
    "        \"label_length\": np.array(label_len, dtype=np.int32),\n",
    "    }, np.zeros(1)\n",
    "\n",
    "def prepare_tf_dataset(dataset, batch_size=8):\n",
    "    def gen():\n",
    "        for mel, text in dataset:\n",
    "            x, y = prepare_inputs(mel, text)\n",
    "            yield x, y\n",
    "\n",
    "    output_signature = (\n",
    "        {\n",
    "            \"spectrogram\": tf.TensorSpec(shape=(None, N_MELS), dtype=tf.float32),\n",
    "            \"labels\": tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "            \"input_length\": tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "            \"label_length\": tf.TensorSpec(shape=(1,), dtype=tf.int32),\n",
    "        },\n",
    "        tf.TensorSpec(shape=(1,), dtype=tf.float32),\n",
    "    )\n",
    "\n",
    "    ds = tf.data.Dataset.from_generator(gen, output_signature=output_signature)\n",
    "    ds = ds.padded_batch(\n",
    "        batch_size,\n",
    "        padded_shapes=(\n",
    "            {\n",
    "                \"spectrogram\": [None, N_MELS],\n",
    "                \"labels\": [None],\n",
    "                \"input_length\": [1],\n",
    "                \"label_length\": [1],\n",
    "            },\n",
    "            [1],\n",
    "        ),\n",
    "        padding_values=(\n",
    "            {\n",
    "                \"spectrogram\": 0.0,\n",
    "                \"labels\": 0,\n",
    "                \"input_length\": 0,\n",
    "                \"label_length\": 0,\n",
    "            },\n",
    "            0.0,\n",
    "        ),\n",
    "    )\n",
    "    return ds.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def text_to_int(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text) if text is not None else \"\"\n",
    "    text = text.lower()\n",
    "    return [char2idx[c] for c in text if c in char2idx]\n",
    "\n",
    "def int_to_text(seq):\n",
    "    return \"\".join(idx2char.get(i, \"\") for i in seq)\n",
    "\n",
    "df = pd.read_csv(os.path.join(OUT_DIR, \"manifest.csv\"))\n",
    "\n",
    "def load_example(row):\n",
    "    mel = np.load(row[\"spec_path\"])\n",
    "    text = text_to_int(row[\"text\"])\n",
    "    return mel, np.array(text, dtype=np.int32)\n",
    "\n",
    "data = [load_example(row) for _, row in df.iterrows()]\n",
    "\n",
    "split = int(len(data) * 0.9)\n",
    "train_data = data[:split]\n",
    "val_data = data[split:]\n",
    "\n",
    "def generator(dataset):\n",
    "    for mel, text in dataset:\n",
    "        yield mel, text\n",
    "\n",
    "train_ds = prepare_tf_dataset(train_data)\n",
    "val_ds = prepare_tf_dataset(val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdf6ed0",
   "metadata": {
    "papermill": {
     "duration": 0.123066,
     "end_time": "2025-11-13T18:05:55.769486",
     "exception": false,
     "start_time": "2025-11-13T18:05:55.646420",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# DeepSpeech2 Model (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef77f308",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:05:56.042131Z",
     "iopub.status.busy": "2025-11-13T18:05:56.041460Z",
     "iopub.status.idle": "2025-11-13T18:05:56.126780Z",
     "shell.execute_reply": "2025-11-13T18:05:56.126190Z"
    },
    "papermill": {
     "duration": 0.213434,
     "end_time": "2025-11-13T18:05:56.127955",
     "exception": false,
     "start_time": "2025-11-13T18:05:55.914521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "N_MELS = 80\n",
    "alphabet = list(string.ascii_lowercase) + [\" \", \"'\", \"<blank>\"]\n",
    "char2idx = {c: i for i, c in enumerate(alphabet)}\n",
    "idx2char = {i: c for c, i in char2idx.items()}\n",
    "\n",
    "def DeepSpeech2_Keras(n_mels=N_MELS, n_classes=len(alphabet)):\n",
    "    input_spectrogram = layers.Input(shape=(None, n_mels), name=\"spectrogram\")\n",
    "    labels = layers.Input(shape=(None,), dtype=\"int32\", name=\"labels\")\n",
    "    input_len = layers.Input(shape=(1,), dtype=\"int32\", name=\"input_length\")\n",
    "    label_len = layers.Input(shape=(1,), dtype=\"int32\", name=\"label_length\")\n",
    "\n",
    "    x = layers.Reshape((-1, n_mels, 1))(input_spectrogram)\n",
    "    x = layers.Conv2D(32, (11, 41), strides=(2, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv2D(32, (11, 21), strides=(1, 2), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Reshape((-1, x.shape[-2] * x.shape[-1]))(x)\n",
    "\n",
    "    for _ in range(3):\n",
    "        x = layers.Bidirectional(layers.GRU(512, return_sequences=True, dropout=0.2))(x)\n",
    "\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    y_pred = layers.Dense(n_classes + 1, activation=\"softmax\", name=\"y_pred\")(x)\n",
    "\n",
    "    # --- CTC Loss Layer ---\n",
    "    def ctc_lambda_func(args):\n",
    "        y_pred, labels, input_len, label_len = args\n",
    "        return K.ctc_batch_cost(labels, y_pred, input_len, label_len)\n",
    "\n",
    "    loss_out = layers.Lambda(ctc_lambda_func, output_shape=(1,), name=\"ctc\")(\n",
    "        [y_pred, labels, input_len, label_len]\n",
    "    )\n",
    "\n",
    "    model = models.Model(\n",
    "        inputs=[input_spectrogram, labels, input_len, label_len],\n",
    "        outputs=loss_out\n",
    "    )\n",
    "\n",
    "    pred_model = models.Model(inputs=input_spectrogram, outputs=y_pred)\n",
    "    return model, pred_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ac572de",
   "metadata": {
    "papermill": {
     "duration": 0.12063,
     "end_time": "2025-11-13T18:05:56.369389",
     "exception": false,
     "start_time": "2025-11-13T18:05:56.248759",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train the Model with model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea63a143",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:05:56.615015Z",
     "iopub.status.busy": "2025-11-13T18:05:56.614397Z",
     "iopub.status.idle": "2025-11-13T18:25:22.002904Z",
     "shell.execute_reply": "2025-11-13T18:25:22.002235Z"
    },
    "papermill": {
     "duration": 1165.513366,
     "end_time": "2025-11-13T18:25:22.004326",
     "exception": false,
     "start_time": "2025-11-13T18:05:56.490960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1763057169.541940      64 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 586ms/step - loss: 310.0273\n",
      "Epoch 1: val_loss improved from inf to 321.15170, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 608ms/step - loss: 309.9264 - val_loss: 321.1517 - learning_rate: 1.0000e-04\n",
      "Epoch 2/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373ms/step - loss: 204.3961\n",
      "Epoch 2: val_loss improved from 321.15170 to 167.40765, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 391ms/step - loss: 204.3408 - val_loss: 167.4077 - learning_rate: 1.0000e-04\n",
      "Epoch 3/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 341ms/step - loss: 138.9478\n",
      "Epoch 3: val_loss improved from 167.40765 to 129.66989, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m132s\u001b[0m 359ms/step - loss: 138.9352 - val_loss: 129.6699 - learning_rate: 1.0000e-04\n",
      "Epoch 4/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 337ms/step - loss: 116.1319\n",
      "Epoch 4: val_loss improved from 129.66989 to 100.64053, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m131s\u001b[0m 355ms/step - loss: 116.1229 - val_loss: 100.6405 - learning_rate: 1.0000e-04\n",
      "Epoch 5/10\n",
      "\u001b[1m  2/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5:33\u001b[0m 912ms/step - loss: 115.3980"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5: val_loss improved from 100.64053 to 99.50379, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 20ms/step - loss: 111.0330 - val_loss: 99.5038 - learning_rate: 1.0000e-04\n",
      "Epoch 6/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - loss: 102.6529\n",
      "Epoch 6: val_loss improved from 99.50379 to 85.32074, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 343ms/step - loss: 102.6435 - val_loss: 85.3207 - learning_rate: 1.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 323ms/step - loss: 87.5297\n",
      "Epoch 7: val_loss improved from 85.32074 to 77.45393, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 341ms/step - loss: 87.5147 - val_loss: 77.4539 - learning_rate: 1.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - loss: 74.5923\n",
      "Epoch 8: val_loss improved from 77.45393 to 69.59663, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 339ms/step - loss: 74.5914 - val_loss: 69.5966 - learning_rate: 1.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - loss: 66.9027\n",
      "Epoch 9: val_loss improved from 69.59663 to 60.96462, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m127s\u001b[0m 345ms/step - loss: 66.9020 - val_loss: 60.9646 - learning_rate: 1.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m  2/368\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:34\u001b[0m 258ms/step - loss: 65.7099\n",
      "Epoch 10: val_loss improved from 60.96462 to 59.19888, saving model to best_deepspeech2.weights.h5\n",
      "\u001b[1m368/368\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 18ms/step - loss: 64.7432 - val_loss: 59.1989 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, Callback\n",
    "import numpy as np\n",
    "\n",
    "model, pred_model = DeepSpeech2_Keras()\n",
    "\n",
    "class StopWhenLossBelow(Callback):\n",
    "    def __init__(self, threshold=0.1):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        loss = logs.get(\"loss\")\n",
    "        if loss is not None and loss < self.threshold:\n",
    "            print(f\"\\nStopping: loss={loss:.4f} < {self.threshold}\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "\n",
    "checkpoint_cb = ModelCheckpoint(\n",
    "    \"best_deepspeech2.weights.h5\",\n",
    "    monitor=\"val_loss\",\n",
    "    save_best_only=True,\n",
    "    save_weights_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr_cb = ReduceLROnPlateau(\n",
    "    monitor=\"val_loss\",\n",
    "    factor=0.5,\n",
    "    patience=2,\n",
    "    verbose=1,\n",
    "    min_lr=1e-6\n",
    ")\n",
    "\n",
    "earlystop_cb = StopWhenLossBelow(threshold=0.1)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=lambda y_true, y_pred: y_pred\n",
    ")\n",
    "if os.path.exists(\"/kaggle/working/best_deepspeech2.weights.h5\"):\n",
    "    model.load_weights(\"best_deepspeech2.weights.h5\")\n",
    "BATCH_SIZE = 32\n",
    "steps_per_epoch = len(train_data) // BATCH_SIZE\n",
    "validation_steps = len(val_data) // BATCH_SIZE\n",
    "\n",
    "EPOCHS = 10\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    callbacks=[checkpoint_cb, reduce_lr_cb, earlystop_cb],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.load_weights(\"best_deepspeech2.weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf544ee",
   "metadata": {
    "papermill": {
     "duration": 0.237424,
     "end_time": "2025-11-13T18:25:22.481968",
     "exception": false,
     "start_time": "2025-11-13T18:25:22.244544",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Evaluate Model on Training and External Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca194a92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:25:22.960326Z",
     "iopub.status.busy": "2025-11-13T18:25:22.959578Z",
     "iopub.status.idle": "2025-11-13T18:25:26.465854Z",
     "shell.execute_reply": "2025-11-13T18:25:26.464890Z"
    },
    "papermill": {
     "duration": 3.748652,
     "end_time": "2025-11-13T18:25:26.467090",
     "exception": false,
     "start_time": "2025-11-13T18:25:22.718438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "GT: many factors were undoubtedly involved in oswald's motivation for the assassination and the commission does not believe\n",
      "Pred: mny fcters were oun dotedly im boled in oswlds motevtion for the ssssintion nd the commission dos not plive\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
      "GT: that it can ascribe to him any one motive or group of motives\n",
      "Pred: bt it comi scrived to him ny one moted or gro r motrs\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step\n",
      "GT: it is apparent however that oswald was moved by an overriding hostility to his environment\n",
      "Pred: it is pprend hewever tht oswld ws moed by in overriding hostility to his invirnment\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow.keras.backend as K\n",
    "\n",
    "model, pred_model = DeepSpeech2_Keras()\n",
    "\n",
    "model.load_weights(\"best_deepspeech2.weights.h5\")\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=lambda y_true, y_pred: y_pred\n",
    ")\n",
    "\n",
    "def greedy_decode_tf(logits):\n",
    "    input_len = np.ones(logits.shape[0]) * logits.shape[1]\n",
    "    decoded, _ = K.ctc_decode(logits, input_length=input_len, greedy=True)\n",
    "    decoded = decoded[0].numpy()\n",
    "    texts = [\"\".join(idx2char.get(i, \"\") for i in seq if i > 0) for seq in decoded]\n",
    "    return texts\n",
    "\n",
    "for i in range(3):\n",
    "    mel, text = val_data[i]\n",
    "    mel_in = np.expand_dims(mel, axis=0)\n",
    "    pred = pred_model.predict(mel_in)\n",
    "    decoded_text = greedy_decode_tf(pred)[0]\n",
    "    out_text = \"\".join([idx2char.get(l, \"\") for l in text])\n",
    "    print(\"GT:\", out_text)\n",
    "    print(\"Pred:\", decoded_text)\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f79d95",
   "metadata": {
    "papermill": {
     "duration": 0.320832,
     "end_time": "2025-11-13T18:25:27.028825",
     "exception": false,
     "start_time": "2025-11-13T18:25:26.707993",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Calculate Word Error Rate (WER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9955b9e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:25:27.527867Z",
     "iopub.status.busy": "2025-11-13T18:25:27.527548Z",
     "iopub.status.idle": "2025-11-13T18:25:37.384798Z",
     "shell.execute_reply": "2025-11-13T18:25:37.383918Z"
    },
    "papermill": {
     "duration": 10.108944,
     "end_time": "2025-11-13T18:25:37.386160",
     "exception": false,
     "start_time": "2025-11-13T18:25:27.277216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jiwer\r\n",
      "  Downloading jiwer-4.0.0-py3-none-any.whl.metadata (3.3 kB)\r\n",
      "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.3.0)\r\n",
      "Collecting rapidfuzz>=3.9.7 (from jiwer)\r\n",
      "  Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (12 kB)\r\n",
      "Downloading jiwer-4.0.0-py3-none-any.whl (23 kB)\r\n",
      "Downloading rapidfuzz-3.14.3-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\r\n",
      "Successfully installed jiwer-4.0.0 rapidfuzz-3.14.3\r\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step\n",
      "WER: 0.6898395721925134\n"
     ]
    }
   ],
   "source": [
    "!pip install jiwer\n",
    "from jiwer import wer\n",
    "\n",
    "gts, preds = [], []\n",
    "for i in range(10):  # 10 прикладів для демонстрації\n",
    "    mel, text = val_data[i]\n",
    "    mel_in = np.expand_dims(mel, axis=0)\n",
    "    pred = pred_model.predict(mel_in)\n",
    "    decoded_text = greedy_decode_tf(pred)[0]\n",
    "    out_text = \"\".join([idx2char.get(l, \"\") for l in text])\n",
    "    gts.append(out_text)\n",
    "    preds.append(decoded_text)\n",
    "\n",
    "print(\"WER:\", wer(gts, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19f7860",
   "metadata": {
    "papermill": {
     "duration": 0.241355,
     "end_time": "2025-11-13T18:25:37.867506",
     "exception": false,
     "start_time": "2025-11-13T18:25:37.626151",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Text Post-processing with SymSpell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0b31837",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-13T18:25:38.343462Z",
     "iopub.status.busy": "2025-11-13T18:25:38.342786Z",
     "iopub.status.idle": "2025-11-13T18:25:43.397842Z",
     "shell.execute_reply": "2025-11-13T18:25:43.397174Z"
    },
    "papermill": {
     "duration": 5.292893,
     "end_time": "2025-11-13T18:25:43.398919",
     "exception": false,
     "start_time": "2025-11-13T18:25:38.106026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting symspellpy\r\n",
      "  Downloading symspellpy-6.9.0-py3-none-any.whl.metadata (3.9 kB)\r\n",
      "Collecting editdistpy>=0.1.3 (from symspellpy)\r\n",
      "  Downloading editdistpy-0.1.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Downloading symspellpy-6.9.0-py3-none-any.whl (2.6 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading editdistpy-0.1.6-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.4/158.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: editdistpy, symspellpy\r\n",
      "Successfully installed editdistpy-0.1.6 symspellpy-6.9.0\r\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step\n",
      "GT: many factors were undoubtedly involved in oswald's motivation for the assassination and the commission does not believe\n",
      "Pred: mny fcters were oun dotidly im boled n oswlds motevtion fore the ssssintion nd the commission dos not plie\n",
      "Corrected: and fibers were of doily do told to oswald motivation fore the ssssintion on the commission don not plot\n",
      "WER before SymSpell: 0.8235294117647058\n",
      "WER after SymSpell: 0.7647058823529411\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "GT: that it can ascribe to him any one motive or group of motives\n",
      "Pred: bt it conscrive to him enyn one mote or gropor motts\n",
      "Corrected: of it conceive to him end one one or proper most\n",
      "WER before SymSpell: 0.6153846153846154\n",
      "WER after SymSpell: 0.6153846153846154\n",
      "----------------------------------------\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step\n",
      "GT: it is apparent however that oswald was moved by an overriding hostility to his environment\n",
      "Pred: it is pprent however tht oswld ws moed by in overriding hostility to his invirnment\n",
      "Corrected: it is spent however hot oswald of more by in overriding hostility to his environment\n",
      "WER before SymSpell: 0.4666666666666667\n",
      "WER after SymSpell: 0.3333333333333333\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "!pip install symspellpy\n",
    "from symspellpy import SymSpell, Verbosity\n",
    "import os\n",
    "sym_spell = SymSpell() \n",
    "word_freq = {}\n",
    "for t in df[\"text\"]:\n",
    "    if not isinstance(t, str):\n",
    "        continue\n",
    "    for w in t.lower().split():\n",
    "        word_freq[w] = word_freq.get(w, 0) + 1\n",
    "\n",
    "dict_file = \"symspell_dict.txt\"\n",
    "with open(dict_file, \"w\", encoding=\"utf-8\") as f:\n",
    "    for w, c in word_freq.items():\n",
    "        f.write(f\"{w} {c}\\n\")\n",
    "        \n",
    "sym_spell.load_dictionary(dict_file, term_index=0, count_index=1)\n",
    "\n",
    "def symspell_correct(text, max_edit_distance=2):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    words = text.split()\n",
    "    corrected = []\n",
    "    for i, w in enumerate(words):\n",
    "        w_lower = w.lower()\n",
    "        if w_lower in sym_spell.words:\n",
    "            corrected.append(w_lower)\n",
    "            continue\n",
    "        suggestions = sym_spell.lookup(w_lower, Verbosity.ALL, max_edit_distance=max_edit_distance)\n",
    "        if not suggestions:\n",
    "            corrected.append(w_lower)\n",
    "            continue\n",
    "        best = max(suggestions, key=lambda s: s.count)\n",
    "        if i > 0 and corrected:\n",
    "            prev = corrected[-1]\n",
    "            for s in suggestions:\n",
    "                if s.term.startswith(prev[:2]) or s.term.endswith(prev[-2:]):\n",
    "                    best = s\n",
    "                    break\n",
    "        corrected.append(best.term)\n",
    "    return \" \".join(corrected)\n",
    "\n",
    "from jiwer import wer\n",
    "for i in range(3):\n",
    "    mel, text = val_data[i]\n",
    "    mel_in = np.expand_dims(mel, axis=0)\n",
    "    pred = pred_model.predict(mel_in)\n",
    "    decoded_text = greedy_decode_tf(pred)[0]\n",
    "    out_text = \"\".join([idx2char.get(l, \"\") for l in text])\n",
    "    corrected_text = symspell_correct(decoded_text)\n",
    "    print(\"GT:\", out_text)\n",
    "    print(\"Pred:\", decoded_text)\n",
    "    print(\"Corrected:\",corrected_text)\n",
    "    print(\"WER before SymSpell:\", wer(out_text, decoded_text))\n",
    "    print(\"WER after SymSpell:\", wer(out_text, corrected_text))\n",
    "    print(\"-\" * 40)\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1159053,
     "sourceId": 1942970,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31155,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1611.454476,
   "end_time": "2025-11-13T18:25:47.175072",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-13T17:58:55.720596",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
